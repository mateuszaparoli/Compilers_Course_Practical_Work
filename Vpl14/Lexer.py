import sys
import enum


class Token:
    """
    This class contains the definition of Tokens. A token has two fields: its
    text and its kind. The "kind" of a token is a constant that identifies it
    uniquely. See the TokenType to know the possible identifiers (if you want).
    You don't need to change this class.
    """
    def __init__(self, tokenText, tokenKind):
        # The token's actual text. Used for identifiers, strings, and numbers.
        self.text = tokenText
        # The TokenType that this token is classified as.
        self.kind = tokenKind


class TokenType(enum.Enum):
    """
    These are the possible tokens. You don't need to change this class at all.
    """

    EOF = -1  # End of file
    NLN = 0  # New line
    WSP = 1  # White Space
    COM = 2  # Comment
    NUM = 3  # Number (integers)
    STR = 4  # Strings
    TRU = 5  # The constant true
    FLS = 6  # The constant false
    VAR = 7  # An identifier
    LET = 8  # The 'let' of the let expression
    INX = 9  # The 'in' of the let expression
    END = 10  # The 'end' of the let expression
    EQL = 201  # x = y
    ADD = 202  # x + y
    SUB = 203  # x - y
    MUL = 204  # x * y
    DIV = 205  # x / y
    LEQ = 206  # x <= y
    LTH = 207  # x < y
    NEG = 208  # ~x
    NOT = 209  # not x
    LPR = 210  # (
    RPR = 211  # )
    ASN = 212  # The assignment '<-' operator
    ORX = 213  # x or y
    AND = 214  # x and y
    IFX = 215  # The 'if' of a conditional expression
    THN = 216  # The 'then' of a conditional expression
    ELS = 217  # The 'else' of a conditional expression
    FNX = 218  # The 'fn' that declares an anonymous function
    ARW = 219  # The '=>' that separates the parameter from the body of function
    TPF = 220  # The arrow that indicates a function type
    COL = 221  # The colon that separates type annotations
    INT = 222  # The int type ('int')
    LGC = 223  # The boolean (logic) type ('bool')

class Lexer:
    
    def __init__(self, source):
        """
        The constructor of the lexer. It receives the string that shall be
        scanned.
        """
        self.source = source
        self.position = 0
        self.length = len(source)

    def _peek(self):
        if self.position >= self.length:
            return "\0"
        return self.source[self.position]

    def _peek_next(self):
        nxt = self.position + 1
        if nxt >= self.length:
            return "\0"
        return self.source[nxt]

    def _advance(self):
        ch = self._peek()
        if self.position < self.length:
            self.position += 1
        return ch

    def tokens(self):
        """
        This method is a token generator: it converts the string encapsulated
        into this object into a sequence of Tokens. Notice that this method
        filters out three kinds of tokens: white-spaces, comments and new lines.

        Examples:

        >>> l = Lexer("1 + 3")
        >>> [tk.kind for tk in l.tokens()]
        [<TokenType.NUM: 3>, <TokenType.ADD: 202>, <TokenType.NUM: 3>]

        >>> l = Lexer('1 * 2\\n')
        >>> [tk.kind for tk in l.tokens()]
        [<TokenType.NUM: 3>, <TokenType.MUL: 204>, <TokenType.NUM: 3>]

        >>> l = Lexer('1 * 2 -- 3\\n')
        >>> [tk.kind for tk in l.tokens()]
        [<TokenType.NUM: 3>, <TokenType.MUL: 204>, <TokenType.NUM: 3>]

        >>> l = Lexer("1 + var")
        >>> [tk.kind for tk in l.tokens()]
        [<TokenType.NUM: 3>, <TokenType.ADD: 202>, <TokenType.VAR: 7>]

        >>> l = Lexer("let v <- 2 in v end")
        >>> [tk.kind.name for tk in l.tokens()]
        ['LET', 'VAR', 'ASN', 'NUM', 'INX', 'VAR', 'END']

        >>> l = Lexer("v: int -> int")
        >>> [tk.kind.name for tk in l.tokens()]
        ['VAR', 'COL', 'INT', 'TPF', 'INT']

        >>> l = Lexer("v: int -> bool")
        >>> [tk.kind.name for tk in l.tokens()]
        ['VAR', 'COL', 'INT', 'TPF', 'LGC']
        """
        token = self.getToken()
        while token.kind != TokenType.EOF:
            if token.kind != TokenType.WSP and token.kind != TokenType.COM \
                    and token.kind != TokenType.NLN:
                yield token
            token = self.getToken()

    def getToken(self):
        """
        Return the next token.
        TODO: Implement this method!
        """
        while True:
            if self.position >= self.length:
                return Token("", TokenType.EOF)

            current_char = self._peek()

            if current_char == "\n":
                self._advance()
                return Token("\n", TokenType.NLN)

            if current_char in " \t\r":
                self._advance()
                return Token(current_char, TokenType.WSP)

            if current_char == "-" and self._peek_next() == "-":
                start = self.position
                self.position += 2
                while self.position < self.length and self.source[self.position] != "\n":
                    self.position += 1
                text = self.source[start:self.position]
                return Token(text, TokenType.COM)

            if current_char == "(" and self._peek_next() == "*":
                start = self.position
                self.position += 2
                while self.position < self.length - 1:
                    if self.source[self.position] == "*" and self.source[self.position + 1] == ")":
                        self.position += 2
                        text = self.source[start:self.position]
                        return Token(text, TokenType.COM)
                    self.position += 1
                raise ValueError("Unterminated block comment")

            if current_char.isdigit():
                start = self.position
                while self.position < self.length and self.source[self.position].isdigit():
                    self.position += 1
                text = self.source[start:self.position]
                return Token(text, TokenType.NUM)

            if current_char.isalpha():
                start = self.position
                while self.position < self.length and (self.source[self.position].isalnum() or self.source[self.position] == "_"):
                    self.position += 1
                text = self.source[start:self.position]
                keywords = {
                    "let": TokenType.LET,
                    "in": TokenType.INX,
                    "end": TokenType.END,
                    "true": TokenType.TRU,
                    "false": TokenType.FLS,
                    "if": TokenType.IFX,
                    "then": TokenType.THN,
                    "else": TokenType.ELS,
                    "or": TokenType.ORX,
                    "and": TokenType.AND,
                    "not": TokenType.NOT,
                    "fn": TokenType.FNX,
                    "int": TokenType.INT,
                    "bool": TokenType.LGC,
                }
                token_kind = keywords.get(text, TokenType.VAR)
                return Token(text, token_kind)

            current_char = self._advance()

            if current_char == "+":
                return Token("+", TokenType.ADD)
            if current_char == "-":
                if self._peek() == ">":
                    self._advance()
                    return Token("->", TokenType.TPF)
                return Token("-", TokenType.SUB)
            if current_char == "*":
                return Token("*", TokenType.MUL)
            if current_char == "/":
                return Token("/", TokenType.DIV)
            if current_char == "<":
                if self._peek() == "-":
                    self._advance()
                    return Token("<-", TokenType.ASN)
                if self._peek() == "=":
                    self._advance()
                    return Token("<=", TokenType.LEQ)
                return Token("<", TokenType.LTH)
            if current_char == "=":
                if self._peek() == ">":
                    self._advance()
                    return Token("=>", TokenType.ARW)
                if self._peek() == "=":
                    self._advance()
                    return Token("==", TokenType.EQL)
                return Token("=", TokenType.EQL)
            if current_char == "~":
                return Token("~", TokenType.NEG)
            if current_char == ":":
                return Token(":", TokenType.COL)
            if current_char == "(":
                return Token("(", TokenType.LPR)
            if current_char == ")":
                return Token(")", TokenType.RPR)

            raise ValueError(f"Unexpected character: {current_char}")